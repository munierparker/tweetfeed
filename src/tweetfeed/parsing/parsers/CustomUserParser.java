/*
 * TweetFeed. Munier Parker, 2016.
 */
package tweetfeed.parsing.parsers;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.util.logging.Level;
import org.antlr.v4.runtime.ANTLRInputStream;
import org.antlr.v4.runtime.CommonTokenStream;
import org.antlr.v4.runtime.RecognitionException;
import org.antlr.v4.runtime.tree.ParseTreeWalker;
import tweetfeed.TweetFeed;
import tweetfeed.parsing.antlrgenerated.user.UserFollowersLexer;
import tweetfeed.parsing.antlrgenerated.user.UserFollowersParser;
import tweetfeed.parsing.listeners.UserParseTreeListener;

/**
 *
 * @author Munier
 *
 * This is a Custom parser designed to parse the user.txt file. See the ANTLR grammar in UserFollowers.g4 in
 * twitterfeed.grammars.
 *
 * ANTLR is a tool that is used to define a set of grammar rules. The grammar rules then instruct ANTLR to generate a
 * lexical analyser and parser to recognise sentences in that specific grammar.
 *
 * ANTLR was used so that even if the requirements change and the grammar has to be extended or made really complex to
 * define user relationships with tweets, then it can be easily extended and modified.
 *
 * In this way, not only is the parser extremely powerful, efficient and extendable, but the UserParsable interface
 * decoupled the Parser implementation from JobConsumer so that any part can be swopped out and changed.
 */
public class CustomUserParser implements UserParsable {

    private File userFile; //The file containing the user relationship

    /**
     * Create a new Custom User File Parser
     *
     * @param userFile the File pointing to the user.txt file
     */
    public CustomUserParser(File userFile) {
        this.userFile = userFile;
    }

    /**
     * Parse the user.txt file using the Lexical Analyser and Parser generated by ANTLR using the UserFollows.g4 grammar
     * in tweetfeed.UserFollowers.g4
     */
    @Override
    public void parseUserFile() {
        FileInputStream userFileInputStream = null;
        try {
            //create an input stream to read the contents
            userFileInputStream = new FileInputStream(userFile);
            //Creating a lexical analyser with the stream
            UserFollowersLexer lexer = new UserFollowersLexer(new ANTLRInputStream(userFileInputStream));

            //Get a list of matched tokens from the lexer
            CommonTokenStream tokens = new CommonTokenStream(lexer);
            // Pass tokens to the parser
            UserFollowersParser parser = new UserFollowersParser(tokens);

            //Create a listener for the correct events are needed to extract the tokens into User Objects
            UserParseTreeListener userParseTreeListener = new UserParseTreeListener(lexer);
            // This is the entry point in the grammar
            UserFollowersParser.UserfollowContext context = parser.userfollow();
            // Create a walker
            ParseTreeWalker walker = new ParseTreeWalker();
            //walk the parse tree and listen for the necessary events
            walker.walk(userParseTreeListener, context);
            TweetFeed.Echo("Parsing '" + userFile.getName() + "' ... DONE.");
        } catch (FileNotFoundException ex) {
            TweetFeed.TweetLogger.log(Level.SEVERE, ex.getMessage());
            TweetFeed.Echo(ex.getMessage());
        } catch (IOException e) {
            TweetFeed.TweetLogger.log(Level.SEVERE, e.getMessage());
            TweetFeed.Echo(e.getMessage());
        } catch (RecognitionException re) {
            TweetFeed.TweetLogger.log(Level.SEVERE, re.getMessage());
            TweetFeed.Echo(re.getMessage());
        } finally {
            if (userFileInputStream != null) {
                try {
                    userFileInputStream.close();
                } catch (IOException e) {
                    TweetFeed.TweetLogger.log(Level.SEVERE, e.getMessage());
                    TweetFeed.Echo(e.getMessage());

                }
            }
        }
    }

}
